---
title: ICLR 2019 Highlights
layout: post
author: Lukas Galke
published: false
---

The International Conference on Learning Representations
([ICLR](https://iclr.cc)) is considered one of the top three core machine
learning conferences along with [NeurIPS](https://neurips.cc) and
[ICML](https://icml.cc). The conference page outlines:

> ICLR is globally renowned for presenting and publishing cutting-edge research
> on all aspects of deep learning used in the fields of artificial
> intelligence, statistics and data science, as well as important application
> areas such as machine vision, computational biology, speech recognition, text
> understanding, gaming, and robotics.

## Highlights

### Causality is invariance to environment

- Pearl's do-calculus on causality graphs is equivalent to invariance given an intervention
- In Peters, Buehlman, Meinshausen 2016 find a representation that is invariant
  to the environment. They select a subset of variables in a dependency graph.
- Conditional adversarial domain adaption implements this concept in neural net fashion
- Key message: decompose $$f$$ into $$\Theta$$ and $$g$$, such that $$g$$ is invariant across environments.

### Maximizing mutual information between local and global representations




## Graph Convolutions

The first day was the workshop day.
I attended the Representation Learning on Graphs and Manifolds.
Will Hamilton uttered a call for the ImageNet moment of graph convolution.

## Day 2

## Day 3

## Day 4

## Day 5



